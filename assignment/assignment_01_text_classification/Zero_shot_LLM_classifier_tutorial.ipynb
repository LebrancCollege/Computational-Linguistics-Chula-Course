{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to run a zero-shot LLM classifier\n",
        "Zero-shot LLM classifier allows you to make a classifier out of a large language model without any training samples. It offers you convenience and flexibility to create a text classifier within minutes.\n",
        "\n",
        "This tutorial will give you an overview of how to create one from Typhoon LLM, which is still free as of Jan 2026.\n",
        "\n",
        "First, go to opentyphoon.ai and find your way to sign up for a free-tier API access and obtain an API key (it is like a password for using the service.) You will need the API key when you use the Python client (it is a library to access the service through API conveniently).\n",
        "\n",
        "Then, you set it up like the code below. Copy and paste your API key into the code below: (obviously don't forget to `pip install openai`)"
      ],
      "metadata": {
        "id": "wbM4reombgii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "client = openai.OpenAI(\n",
        "    api_key = \"\",\n",
        "    base_url=\"https://api.opentyphoon.ai/v1\"\n",
        ")"
      ],
      "metadata": {
        "id": "e2NuNZsLbaPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, write a function that takes in the client object (because it contains the API key and API endpoint), and a list of texts that you want to classify. The function will return a list of labels. The list of texts should be the same length as the list of labels.\n",
        "\n",
        "Note that you want to classify 5-20 texts per function call.\n",
        "\n",
        "- One text per call is too slow and too expensive.\n",
        "- Too many texts per call will cause the LLM to make more mistakes (like return too few labels.)\n",
        "\n",
        "You need to change the prompt to match the label definitions of your task."
      ],
      "metadata": {
        "id": "UmnMWG2Rc-1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def classifier_many_rows(client, text_list):\n",
        "    prompt = \"\"\"\n",
        "    You are a sentiment classifier.\n",
        "\n",
        "    Classify each input text into exactly one label:\n",
        "    POSITIVE: the writer of the text expresses positive attitude\n",
        "    NEGATIVE: the writer of the text expresses negative attitude\n",
        "    NEUTRAL: the text does not reflect the positive or negative attitude\n",
        "\n",
        "    Rules:\n",
        "    - Return one label per input text\n",
        "    - Preserve the original order\n",
        "    - Output must be a JSON array of labels\n",
        "    - Do not include explanations or extra text\n",
        "    \"\"\"\n",
        "    input_text = json.dumps(text_list)\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"typhoon-v2.5-30b-a3b-instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ]\n",
        "    )\n",
        "    raw_output = response.choices[0].message.content\n",
        "    return json.loads(raw_output)"
      ],
      "metadata": {
        "id": "qdrnkuAJc-EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [\n",
        "  \"บริการดีมาก ประทับใจ\",\n",
        "  \"แย่มาก ไม่แนะนำ\",\n",
        "  \"ก็โอเค ไม่ดีไม่แย่\"\n",
        "]\n",
        "classifier_many_rows(client, input_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7gZpSyKgklC",
        "outputId": "9dcc3017-ab70-4857-8c57-9f5a5417656c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NEUTRAL', 'NEUTRAL', 'NEUTRAL']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}